{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4c0fbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38499d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('../Dataset/cashewgrade.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ea4ad04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X = data.drop('grade', axis=1)\n",
    "y = data['grade']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e038272b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the features\n",
    "# Define a list of models to compare\n",
    "models = [LogisticRegression(), SVC(), DecisionTreeClassifier(), RandomForestClassifier(), GradientBoostingClassifier(), AdaBoostClassifier()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa6442d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for LogisticRegression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         180       0.64      0.75      0.69        61\n",
      "         210       0.43      0.24      0.31        82\n",
      "         240       0.45      0.59      0.51        63\n",
      "         320       0.49      0.63      0.55        73\n",
      "         400       0.74      0.57      0.65        70\n",
      "\n",
      "    accuracy                           0.54       349\n",
      "   macro avg       0.55      0.56      0.54       349\n",
      "weighted avg       0.54      0.54      0.53       349\n",
      "\n",
      "Accuracy: 0.5415472779369628\n",
      "Classification Report for SVC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         180       0.84      0.85      0.85        61\n",
      "         210       0.53      0.30      0.39        82\n",
      "         240       0.42      0.62      0.50        63\n",
      "         320       0.64      0.74      0.69        73\n",
      "         400       0.88      0.80      0.84        70\n",
      "\n",
      "    accuracy                           0.65       349\n",
      "   macro avg       0.66      0.66      0.65       349\n",
      "weighted avg       0.66      0.65      0.64       349\n",
      "\n",
      "Accuracy: 0.6475644699140402\n",
      "Classification Report for DecisionTreeClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         180       0.86      0.79      0.82        61\n",
      "         210       0.64      0.52      0.58        82\n",
      "         240       0.48      0.65      0.55        63\n",
      "         320       0.59      0.58      0.58        73\n",
      "         400       0.80      0.79      0.79        70\n",
      "\n",
      "    accuracy                           0.66       349\n",
      "   macro avg       0.67      0.66      0.66       349\n",
      "weighted avg       0.67      0.66      0.66       349\n",
      "\n",
      "Accuracy: 0.6561604584527221\n",
      "Classification Report for RandomForestClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         180       0.86      0.89      0.87        61\n",
      "         210       0.71      0.54      0.61        82\n",
      "         240       0.55      0.68      0.61        63\n",
      "         320       0.73      0.84      0.78        73\n",
      "         400       0.94      0.83      0.88        70\n",
      "\n",
      "    accuracy                           0.74       349\n",
      "   macro avg       0.76      0.75      0.75       349\n",
      "weighted avg       0.76      0.74      0.74       349\n",
      "\n",
      "Accuracy: 0.7449856733524355\n",
      "Classification Report for GradientBoostingClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         180       0.84      0.89      0.86        61\n",
      "         210       0.73      0.56      0.63        82\n",
      "         240       0.53      0.67      0.59        63\n",
      "         320       0.72      0.74      0.73        73\n",
      "         400       0.90      0.86      0.88        70\n",
      "\n",
      "    accuracy                           0.73       349\n",
      "   macro avg       0.74      0.74      0.74       349\n",
      "weighted avg       0.74      0.73      0.73       349\n",
      "\n",
      "Accuracy: 0.7335243553008596\n",
      "Classification Report for AdaBoostClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         180       0.00      0.00      0.00        61\n",
      "         210       0.00      0.00      0.00        82\n",
      "         240       0.25      0.81      0.38        63\n",
      "         320       0.68      0.56      0.62        73\n",
      "         400       0.76      0.93      0.83        70\n",
      "\n",
      "    accuracy                           0.45       349\n",
      "   macro avg       0.34      0.46      0.37       349\n",
      "weighted avg       0.34      0.45      0.37       349\n",
      "\n",
      "Accuracy: 0.4498567335243553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate each model\n",
    "for model in models:\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    # Make predictions on test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    # Print the classification report\n",
    "    print(\"Classification Report for\", type(model).__name__)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85a73a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([240, 240, 400, 240, 400, 240, 240, 320, 400, 240, 240, 320, 320,\n",
       "       240, 240, 320, 240, 320, 320, 320, 400, 240, 240, 240, 320, 240,\n",
       "       240, 240, 320, 240, 240, 240, 240, 400, 240, 240, 320, 240, 240,\n",
       "       240, 240, 400, 400, 320, 320, 240, 240, 240, 400, 400, 320, 240,\n",
       "       240, 320, 320, 320, 320, 240, 240, 240, 240, 400, 240, 400, 240,\n",
       "       240, 240, 320, 400, 400, 240, 240, 240, 240, 240, 240, 400, 240,\n",
       "       240, 240, 240, 240, 240, 400, 240, 320, 400, 240, 240, 400, 400,\n",
       "       240, 320, 240, 400, 320, 240, 240, 240, 240, 240, 240, 240, 320,\n",
       "       240, 320, 240, 240, 240, 400, 240, 240, 400, 400, 400, 240, 240,\n",
       "       240, 320, 240, 240, 400, 240, 240, 240, 400, 320, 400, 240, 400,\n",
       "       240, 240, 240, 240, 240, 240, 400, 400, 320, 240, 320, 400, 240,\n",
       "       240, 240, 400, 240, 240, 240, 400, 240, 240, 400, 400, 320, 400,\n",
       "       400, 240, 400, 400, 320, 240, 240, 400, 240, 240, 400, 240, 240,\n",
       "       400, 240, 240, 320, 240, 320, 240, 240, 240, 320, 240, 400, 320,\n",
       "       400, 320, 240, 240, 320, 320, 240, 240, 240, 400, 240, 320, 240,\n",
       "       320, 320, 240, 240, 240, 400, 320, 320, 400, 240, 240, 240, 240,\n",
       "       240, 240, 400, 400, 320, 240, 400, 400, 240, 240, 240, 240, 240,\n",
       "       240, 240, 320, 240, 240, 240, 240, 240, 400, 400, 400, 400, 240,\n",
       "       240, 400, 240, 240, 400, 240, 240, 400, 400, 240, 320, 400, 320,\n",
       "       400, 240, 240, 240, 240, 400, 320, 240, 240, 400, 320, 400, 240,\n",
       "       320, 400, 400, 240, 240, 320, 240, 240, 400, 240, 240, 320, 240,\n",
       "       400, 240, 240, 400, 240, 240, 240, 240, 400, 400, 240, 320, 240,\n",
       "       240, 400, 400, 400, 240, 240, 240, 240, 240, 240, 240, 400, 240,\n",
       "       400, 240, 400, 240, 240, 240, 320, 320, 240, 240, 320, 400, 400,\n",
       "       400, 240, 240, 240, 240, 400, 400, 400, 240, 240, 240, 240, 240,\n",
       "       400, 320, 240, 320, 320, 400, 240, 240, 240, 240, 320, 240, 240,\n",
       "       320, 400, 400, 320, 240, 240, 240, 240, 240, 240, 240], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import joblib\n",
    "  \n",
    "  \n",
    "# Save the model as a pickle in a file\n",
    "joblib.dump(model, 'BestClassifier.model')\n",
    "  \n",
    "# Load the model from the file\n",
    "bc_from_joblib = joblib.load('BestClassifier.model')\n",
    "  \n",
    "# Use the loaded model to make predictions\n",
    "bc_from_joblib.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94121737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[240 240 400 240 400 240 240 320 400 240 240 320 320 240 240 320 240 320\n",
      " 320 320 400 240 240 240 320 240 240 240 320 240 240 240 240 400 240 240\n",
      " 320 240 240 240 240 400 400 320 320 240 240 240 400 400 320 240 240 320\n",
      " 320 320 320 240 240 240 240 400 240 400 240 240 240 320 400 400 240 240\n",
      " 240 240 240 240 400 240 240 240 240 240 240 400 240 320 400 240 240 400\n",
      " 400 240 320 240 400 320 240 240 240 240 240 240 240 320 240 320 240 240\n",
      " 240 400 240 240 400 400 400 240 240 240 320 240 240 400 240 240 240 400\n",
      " 320 400 240 400 240 240 240 240 240 240 400 400 320 240 320 400 240 240\n",
      " 240 400 240 240 240 400 240 240 400 400 320 400 400 240 400 400 320 240\n",
      " 240 400 240 240 400 240 240 400 240 240 320 240 320 240 240 240 320 240\n",
      " 400 320 400 320 240 240 320 320 240 240 240 400 240 320 240 320 320 240\n",
      " 240 240 400 320 320 400 240 240 240 240 240 240 400 400 320 240 400 400\n",
      " 240 240 240 240 240 240 240 320 240 240 240 240 240 400 400 400 400 240\n",
      " 240 400 240 240 400 240 240 400 400 240 320 400 320 400 240 240 240 240\n",
      " 400 320 240 240 400 320 400 240 320 400 400 240 240 320 240 240 400 240\n",
      " 240 320 240 400 240 240 400 240 240 240 240 400 400 240 320 240 240 400\n",
      " 400 400 240 240 240 240 240 240 240 400 240 400 240 400 240 240 240 320\n",
      " 320 240 240 320 400 400 400 240 240 240 240 400 400 400 240 240 240 240\n",
      " 240 400 320 240 320 320 400 240 240 240 240 320 240 240 320 400 400 320\n",
      " 240 240 240 240 240 240 240]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf23206",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
